<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Emotion Tracker - TeamPulse</title>
  <link rel="stylesheet" href="css/dashboard.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
  <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
  <div class="dashboard-container">
    <!-- Sidebar -->
    <aside class="sidebar">
      <div class="sidebar-header">
        <h2>TeamPulse</h2>
      </div>
      <nav>
        <ul>
          <li><a href="dashboard.html"><i class="fas fa-chart-line"></i>Dashboard</a></li>
          <li><a href="emotion-input.html"><i class="fas fa-face-smile"></i>Emotion Input</a></li>
          <li><a href="emotion-tracker.html" class="active"><i class="fas fa-video"></i>Emotion Tracker</a></li>
          <li><a href="history.html"><i class="fas fa-history"></i>History</a></li>
          <li><a href="feedback.html"><i class="fas fa-comments"></i>Feedback</a></li>
          <li><a href="settings.html"><i class="fas fa-gear"></i>Settings</a></li>
        </ul>
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
      <div class="section-header">
        <h2>Real-Time Emotion Tracker</h2>
        <p>Detect facial and voice-based emotions in real-time</p>
      </div>

      <div style="display: flex; flex-wrap: wrap; gap: 2rem;">
        <div>
          <video id="video" width="480" height="360" autoplay muted></video>
          <canvas id="overlay" style="position: absolute;"></canvas>
          <div style="margin-top: 1rem;">
            <button id="startAudio" class="btn"><i class="fas fa-microphone"></i> Start Voice Detection</button>
          </div>
        </div>
        <div>
          <h3>Detected Emotions</h3>
          <div id="emojis" style="font-size: 2rem; display: flex; gap: 1rem;"></div>
          <canvas id="emotionChart" width="400" height="300"></canvas>
        </div>
      </div>
    </main>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const emojis = document.getElementById('emojis');
    const chartCtx = document.getElementById('emotionChart').getContext('2d');
    const startAudioBtn = document.getElementById('startAudio');

    const emojiMap = {
      happy: "😃",
      sad: "😢",
      angry: "😡",
      surprised: "😲",
      fearful: "😱",
      disgusted: "🤮",
      neutral: "😐"
    };

    let chart;

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (err) {
        alert('Kamera tidak tersedia atau tidak diizinkan.');
        console.error(err);
      }
    }

    function updateChart(emotions) {
      const labels = Object.keys(emojiMap);
      const data = labels.map(label => emotions[label] || 0);

      if (!chart) {
        chart = new Chart(chartCtx, {
          type: 'bar',
          data: {
            labels,
            datasets: [{
              label: 'Confidence',
              backgroundColor: '#3498db',
              data
            }]
          },
          options: {
            scales: {
              y: { beginAtZero: true, max: 1 }
            }
          }
        });
      } else {
        chart.data.datasets[0].data = data;
        chart.update();
      }
    }

    function updateEmojis(emotions) {
      const sorted = Object.entries(emotions).sort((a, b) => b[1] - a[1]);
      const top3 = sorted.slice(0, 3);
      emojis.innerHTML = top3.map(([emo]) => emojiMap[emo]).join(' ');
    }

    function simulateAudioEmotion() {
      return {
        happy: Math.random() * 0.6 + 0.2,
        sad: Math.random() * 0.4,
        angry: Math.random() * 0.3,
        neutral: Math.random() * 0.6
      };
    }

    startAudioBtn.addEventListener('click', async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const audioContext = new AudioContext();
        const source = audioContext.createMediaStreamSource(stream);
        const analyser = audioContext.createAnalyser();
        source.connect(analyser);

        setInterval(() => {
          const emotionData = simulateAudioEmotion();
          updateChart(emotionData);
          updateEmojis(emotionData);
        }, 2000);
      } catch (err) {
        console.error('Microphone error:', err);
        alert('Tidak dapat mengakses mikrofon.');
      }
    });

    video.addEventListener('play', () => {
      const displaySize = { width: video.width, height: video.height };
      canvas.width = video.width;
      canvas.height = video.height;
      const context = canvas.getContext('2d');

      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        context.clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceExpressions(canvas, resizedDetections);

        if (resizedDetections.length > 0) {
          updateChart(resizedDetections[0].expressions);
          updateEmojis(resizedDetections[0].expressions);
        }
      }, 500);
    });

    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('models'),
      faceapi.nets.faceExpressionNet.loadFromUri('models')
    ]).then(startVideo);
  </script>
</body>
</html>
